{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c5578e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444da916",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:\\\\Users\\\\kyles\\\\Desktop\\\\CS5100\\\\Final_Project\\\\pose_landmarker_heavy.task\"\n",
    "min_pose_detection_confidence = 0.5\n",
    "min_pose_presence_confidence = 0.5\n",
    "min_tracking_confidence = 0.5\n",
    "num_poses = 1\n",
    "last_timestamp_ms = 0\n",
    "labels = [\n",
    "    'Right Knee',\n",
    "    'Left Knee',\n",
    "    'Right Ankle',\n",
    "    'Left Ankle',\n",
    "    'Right Heel',\n",
    "    'Left Heel',\n",
    "    'Right Foot Index',\n",
    "    'Left Foot Index'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb39ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = vision.PoseLandmarkerOptions(base_options=base_options,\n",
    "                                      running_mode=vision.RunningMode.VIDEO,\n",
    "                                      num_poses=num_poses,\n",
    "                                      min_pose_detection_confidence=min_pose_detection_confidence,\n",
    "                                      min_pose_presence_confidence=min_pose_presence_confidence,\n",
    "                                      min_tracking_confidence=min_tracking_confidence,\n",
    "                                      output_segmentation_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14921593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_skeleton(detection_result):\n",
    "    pose_landmarks_list = detection_result.pose_landmarks\n",
    "    blank = np.zeros((500, 800, 3), np.uint8)\n",
    "    \n",
    "    for idx in range(len(pose_landmarks_list)):\n",
    "        pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "        pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        pose_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(\n",
    "                x=landmark.x,\n",
    "                y=landmark.y,\n",
    "                z=landmark.z) for landmark in pose_landmarks\n",
    "        ])\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            blank,\n",
    "            pose_landmarks_proto,\n",
    "            mp.solutions.pose.POSE_CONNECTIONS,\n",
    "            mp.solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "    return blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc05695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    pose_landmarks_list = detection_result.pose_landmarks\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "    # Loop through the detected poses to visualize.\n",
    "    for idx in range(len(pose_landmarks_list)):\n",
    "        pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "        pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        pose_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(\n",
    "                x=landmark.x,\n",
    "                y=landmark.y,\n",
    "                z=landmark.z) for landmark in pose_landmarks\n",
    "        ])\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_image,\n",
    "            pose_landmarks_proto,\n",
    "            mp.solutions.pose.POSE_CONNECTIONS,\n",
    "            mp.solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "    return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "f5a54e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lower_half_data(pose_data, x, y):\n",
    "    lower_half_data = []\n",
    "    trimmed_data = pose_data[x:y]\n",
    "\n",
    "    for i in range(len(trimmed_data)):\n",
    "        for each in trimmed_data[i].pose_landmarks:\n",
    "            lower_half_data.append(each[23::])\n",
    "    return lower_half_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "7d6dbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_range(data, x, y, save):\n",
    "    test_range = data[x:y]\n",
    "    path = r'C:\\Users\\kyles\\Desktop\\CS5100\\Final_Project\\skeleton_data'\n",
    "    for i in range(len(test_range)):\n",
    "        out_file = shortened + '_' + str(i) + '.jpg'\n",
    "        test_output = draw_skeleton(test_range[i])\n",
    "        if save:\n",
    "            cv2.imwrite(os.path.join(path, out_file), test_output)\n",
    "            continue\n",
    "        while True:\n",
    "            cv2.imshow('result', test_output)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "4371020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output(labels, data):\n",
    "    output = []\n",
    "    line = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(labels)):\n",
    "            data_point = [labels[j], data[i][j]]\n",
    "            line.append(data_point)\n",
    "        output.append(line)\n",
    "        line = []\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b265d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1) Resize and convert frame from RGB to BGR\\n2) Detect poses\\n    - z represents distance -- we want closer (penalty taker) pose\\n    - append relevant data to lists for feature extraction\\n3) Display image with pose draw onto it\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "1) Resize and convert frame from RGB to BGR\n",
    "2) Detect poses\n",
    "    - z represents distance -- we want closer (penalty taker) pose\n",
    "    - append relevant data to lists for feature extraction\n",
    "3) Display image with pose draw onto it\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "ad8c37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_data = []\n",
    "mp_data = []\n",
    "pose_draw_data = []\n",
    "time_stamps = []\n",
    "\n",
    "video_source = \"C:\\\\Users\\\\kyles\\\\Desktop\\\\CS5100\\\\Final_Project\\\\Project_Data\\\\PEN70.mp4\"\n",
    "shortened = video_source[-9:-4]\n",
    "with vision.PoseLandmarker.create_from_options(options) as landmarker:\n",
    "    # Use OpenCV’s VideoCapture to start capturing from the webcam.\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    # Create a loop to read the latest frame from the camera using VideoCapture#read()\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            \n",
    "            break\n",
    "           \n",
    "        #image = cv2.flip(image, 1)\n",
    "        # Convert the frame received from OpenCV to a MediaPipe’s Image object.\n",
    "        mp_image = mp.Image(\n",
    "            image_format=mp.ImageFormat.SRGB,\n",
    "            data=cv2.cvtColor(image[200:800, 500:1200], cv2.COLOR_BGR2RGB))\n",
    "        timestamp_ms = int(cv2.getTickCount() / cv2.getTickFrequency() * 1000)\n",
    "        result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "        pose_data.append(result.pose_world_landmarks)\n",
    "        annotated_image = draw_landmarks_on_image(mp_image.numpy_view(), result)\n",
    "        \n",
    "        if result.pose_world_landmarks:\n",
    "            if result.pose_world_landmarks[0][0].z > -.3 or result.pose_world_landmarks[0][1].z > -.3:\n",
    "                # get frame_ms -- append to list\n",
    "                frame_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                time_stamps.append(frame_ms / 1000)\n",
    "                # draw frames\n",
    "                pose_draw_data.append(result)\n",
    "                mp_data.append(mp_image)\n",
    "               \n",
    "            \n",
    "        \n",
    "        cv2.imshow(\"MediaPipe Pose Landmark\", cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "1f0c0f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 28\n",
    "y = 33\n",
    "test_image_range(pose_draw_data, x, y, False)\n",
    "\n",
    "lower_output = get_lower_half_data(pose_draw_data, x, y)\n",
    "final_output = create_output(labels, lower_output)\n",
    "len(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "c2e0426c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_times = time_stamps[x:y]\n",
    "output_with_times = list(zip(selected_times, final_output))\n",
    "len(output_with_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "64b0eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(data, filename):\n",
    "    with open(filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([])\n",
    "        writer.writerows(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "1cc6831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.csv'\n",
    "write_to_csv(output_with_times, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9ae8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
